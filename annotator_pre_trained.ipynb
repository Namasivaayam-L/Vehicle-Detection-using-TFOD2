{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "# from object_detection.utils import visualization_utils as vis_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir):\n",
    "    model = tf.saved_model.load(model_dir)\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "    return image_rgb, image_expanded\n",
    "\n",
    "def run_inference(model, image):\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "    model_fn = model.signatures['serving_default']\n",
    "    output_dict = model_fn(input_tensor)\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key: value[0, :num_detections].numpy() for key, value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(image_path, output_dict, label_map_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    confidence_threshold = 0.5  # Confidence threshold for annotations\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(label_map_path)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "\n",
    "    for i in range(output_dict['num_detections']):\n",
    "        class_id = output_dict['detection_classes'][i]\n",
    "        class_label = category_index[class_id]['name']\n",
    "        score = output_dict['detection_scores'][i]\n",
    "        if score > confidence_threshold:\n",
    "            ymin, xmin, ymax, xmax = output_dict['detection_boxes'][i]\n",
    "            xmins.append(xmin)\n",
    "            xmaxs.append(xmax)\n",
    "            ymins.append(ymin)\n",
    "            ymaxs.append(ymax)\n",
    "            classes.append(class_id)\n",
    "            classes_text.append(class_label.encode('utf8'))\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    _, encoded_image = cv2.imencode('.jpg', image_rgb)\n",
    "    encoded_image_data = encoded_image.tobytes()\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(image_path.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(image_path.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths and parameters\n",
    "model_name = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
    "model_dir = '../models/research/object_detection/'\n",
    "model_dir = str(pathlib.Path(model_dir)/model_name/\"saved_model\")\n",
    "  # Path to the directory containing the saved model\n",
    "image_dir = './data/resized_640x640/'  # Path to the directory containing the unlabeled images\n",
    "output_dir = './annotations/'  # Output directory to store the generated TFRecord files\n",
    "label_map_path = '../models/research/object_detection/data/mscoco_label_map.pbtxt'  # Path to the label map file\n",
    "\n",
    "# Load the pretrained model\n",
    "model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the unlabeled images\n",
    "# image_files = os.listdir(image_dir)\n",
    "img_count=0\n",
    "for folder in os.listdir(image_dir):\n",
    "    if not folder=='bluefox_2016-10-04-14-22-41_bag' and not folder=='bluefox_2016-09-30-15-19-35_bag':\n",
    "        for image_file in os.listdir(os.path.join(image_dir,folder)):\n",
    "            # print(folder,os.path.join(image_dir,folder),image_file)\n",
    "            image_path = os.path.join(image_dir,folder, image_file)\n",
    "            # Preprocess the image\n",
    "            # image_rgb, image_expanded = preprocess_image(image_path)\n",
    "            image_np = np.array(cv2.imread(str(image_path)))\n",
    "            tfrecord_filename = os.path.splitext(image_file)[0] + '.tfrecord'\n",
    "            tfrecord_path = os.path.join(output_dir,folder, tfrecord_filename)\n",
    "            # Run inference on the image\n",
    "            # output_dict = run_inference(model, image_expanded)\n",
    "            if not os.path.exists(tfrecord_path):\n",
    "                output_dict = run_inference(model, image = image_np)\n",
    "\n",
    "                # Visualize the results on the image\n",
    "                # annotated_image = visualize_results(image_rgb, output_dict, label_map_path, threshold=confidence_threshold)\n",
    "\n",
    "                # Save the annotated image\n",
    "                # annotated_image_path = os.path.join(output_dir, image_file)\n",
    "                # cv2.imwrite(annotated_image_path, annotated_image)\n",
    "\n",
    "                # Save the annotations in TFRecord format\n",
    "                tf_example = create_tf_example(image_path, output_dict, label_map_path)\n",
    "                tfrecord_filename = os.path.splitext(image_file)[0] + '.tfrecord'\n",
    "                if os.path.exists(os.path.join(output_dir,folder)):pass\n",
    "                else: os.makedirs(os.path.join(output_dir,folder))\n",
    "                tfrecord_path = os.path.join(output_dir,folder, tfrecord_filename)\n",
    "\n",
    "                with tf.io.TFRecordWriter(tfrecord_path) as writer:\n",
    "                    writer.write(tf_example.SerializeToString())\n",
    "                img_count+=1\n",
    "                print(tfrecord_path,img_count)\n",
    "            else:\n",
    "                img_count+=1\n",
    "                pass\n",
    "print(\"Annotation generation and TFRecord conversion complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
